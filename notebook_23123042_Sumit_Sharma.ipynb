{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823b2373",
   "metadata": {},
   "source": [
    "# ðŸ““ Automated Metadata Generation - Final Notebook (Standalone)\n",
    "\n",
    "This notebook extracts and generates metadata from documents using OCR and LLMs.\n",
    "\n",
    "- Supports: PDF, DOCX, TXT, RTF, ODT, HTML, JPG, PNG\n",
    "- Uses: Tesseract, HuggingFace Transformers, KeyBERT\n",
    "- Exports: JSON + CSV\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c9f0e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (4.52.4)\n",
      "Requirement already satisfied: keybert in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (0.9.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (4.1.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pdf2image in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (1.17.0)\n",
      "Requirement already satisfied: odfpy in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (1.4.1)\n",
      "Requirement already satisfied: striprtf in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (0.0.29)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (4.13.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (2.3.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (8.1.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from keybert) (14.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from keybert) (1.6.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from odfpy) (0.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (8.28.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=0.22.2->keybert) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=0.22.2->keybert) (3.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sumit sharma\\appdata\\roaming\\python\\python313\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers keybert sentence-transformers pytesseract pdf2image odfpy striprtf beautifulsoup4 pandas ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21dc5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import docx\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from odf.opendocument import load\n",
    "from odf.text import P\n",
    "from bs4 import BeautifulSoup\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726f9bb",
   "metadata": {},
   "source": [
    "## ðŸ“ Upload Your Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5187ae66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe43903c60c4ef8825e06aeb8f7b1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c8cb62104e47158cbd901f0ccedd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='OCR Mode:', options=('Auto (Recommended)', 'Force OCR'), style=ToggleButtonsStyle(dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload = widgets.FileUpload(accept='', multiple=False)\n",
    "display(upload)\n",
    "\n",
    "ocr_toggle = widgets.ToggleButtons(\n",
    "    options=[\"Auto (Recommended)\", \"Force OCR\"],\n",
    "    description='OCR Mode:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "display(ocr_toggle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4686f8c",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Save Uploaded File Temporarily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcdebf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_uploaded_file(upload):\n",
    "    for file_info in upload.value:\n",
    "        name = file_info['name']\n",
    "        suffix = os.path.splitext(name)[-1]\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:\n",
    "            tmp.write(file_info['content'])\n",
    "            return tmp.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c9634e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ File size: 1.26 MB\n",
      "ðŸ“Š Avg characters per page: 3240.69\n",
      "\n",
      "--- Extracted Text (first 1000 chars) ---\n",
      "\n",
      "arXiv:2506.18854v1  [astro-ph.HE]  23 Jun 2025\n",
      "Comparative analysis of machine learning techniques for feature selection and classification\n",
      "of Fast Radio Bursts\n",
      "Ailton J. B. JÂ´unior,1, âˆ—JÂ´eferson A. S. Fortunato\n",
      ",2, â€  Leonardo J. Silvestre\n",
      ",3, â€¡ Thonimar V. Alencar\n",
      ",4, Â§ and Wiliam S. HipÂ´olito-Ricaldi\n",
      "4, 5, Â¶\n",
      "1Departamento de ComputaÂ¸cËœao e EletrË†onica, CEUNES,\n",
      "Universidade Federal do EspÂ´Ä±rito Santo (UFES), Rodovia BR 101 Norte, km. 60,\n",
      "CEP 29.940-540, SËœao Mateus, ES, Brazil\n",
      "2High Energy Physics, Cosmology & Astrophysics Theory (HEPCAT) Group,\n",
      "Department of Mathematics and Applied Mathematics,\n",
      "University of Cape Town, Cape Town 7700, South Africa\n",
      "3Departamento de ComputaÂ¸cËœao e EletrË†onica, CEUNES,\n",
      "Universidade Federal do EspÂ´Ä±rito Santo, Rodovia BR 101 Norte, km. 60,\n",
      "CEP 29.940-540, SËœao Mateus, ES, Brazil\n",
      "4Departamento de CiË†encias Naturais, CEUNES, Universidade Federal do EspÂ´Ä±rito Santo, Rodovia BR 101 Norte, km. 60,\n",
      "CEP 29.940-540, SËœao Mateus, ES, Brazil\n",
      "5NÂ´ucleo Cosmo-UFES, C\n"
     ]
    }
   ],
   "source": [
    "file_path = save_uploaded_file(upload)\n",
    "force_ocr = ocr_toggle.value == \"Force OCR\"\n",
    "\n",
    "if file_path:\n",
    "    text = extract_text(file_path, force_ocr=force_ocr)\n",
    "    print(\"\\n--- Extracted Text (first 1000 chars) ---\\n\")\n",
    "    print(text[:1000])\n",
    "else:\n",
    "    print(\"âŒ No file uploaded. Please select a file before proceeding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dba6c2",
   "metadata": {},
   "source": [
    "## ðŸ“„ Extract Text (with OCR if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e462c934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ File size: 1.26 MB\n",
      "ðŸ“Š Avg characters per page: 3240.69\n",
      "\n",
      "--- Extracted Text (first 1000 chars) ---\n",
      "\n",
      "arXiv:2506.18854v1  [astro-ph.HE]  23 Jun 2025\n",
      "Comparative analysis of machine learning techniques for feature selection and classification\n",
      "of Fast Radio Bursts\n",
      "Ailton J. B. JÂ´unior,1, âˆ—JÂ´eferson A. S. Fortunato\n",
      ",2, â€  Leonardo J. Silvestre\n",
      ",3, â€¡ Thonimar V. Alencar\n",
      ",4, Â§ and Wiliam S. HipÂ´olito-Ricaldi\n",
      "4, 5, Â¶\n",
      "1Departamento de ComputaÂ¸cËœao e EletrË†onica, CEUNES,\n",
      "Universidade Federal do EspÂ´Ä±rito Santo (UFES), Rodovia BR 101 Norte, km. 60,\n",
      "CEP 29.940-540, SËœao Mateus, ES, Brazil\n",
      "2High Energy Physics, Cosmology & Astrophysics Theory (HEPCAT) Group,\n",
      "Department of Mathematics and Applied Mathematics,\n",
      "University of Cape Town, Cape Town 7700, South Africa\n",
      "3Departamento de ComputaÂ¸cËœao e EletrË†onica, CEUNES,\n",
      "Universidade Federal do EspÂ´Ä±rito Santo, Rodovia BR 101 Norte, km. 60,\n",
      "CEP 29.940-540, SËœao Mateus, ES, Brazil\n",
      "4Departamento de CiË†encias Naturais, CEUNES, Universidade Federal do EspÂ´Ä±rito Santo, Rodovia BR 101 Norte, km. 60,\n",
      "CEP 29.940-540, SËœao Mateus, ES, Brazil\n",
      "5NÂ´ucleo Cosmo-UFES, C\n"
     ]
    }
   ],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "poppler_path = r\"C:\\Program Files\\poppler-24.08.0\\Library\\bin\"\n",
    "\n",
    "def extract_text(file_path, force_ocr=False):\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "\n",
    "    def ocr_pdf(path):  # helper\n",
    "        return \"\\n\".join([pytesseract.image_to_string(img) for img in convert_from_path(path, poppler_path=poppler_path)])\n",
    "\n",
    "    if ext == \".txt\":\n",
    "        return open(file_path, \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "    elif ext == \".docx\":\n",
    "        return \"\\n\".join([p.text for p in docx.Document(file_path).paragraphs])\n",
    "\n",
    "    elif ext == \".odt\":\n",
    "        doc = load(file_path)\n",
    "        return \"\\n\".join([p.firstChild.data for p in doc.getElementsByType(P) if p.firstChild])\n",
    "\n",
    "    elif ext in [\".html\", \".htm\"]:\n",
    "        return BeautifulSoup(open(file_path, encoding=\"utf-8\").read(), \"html.parser\").get_text()\n",
    "\n",
    "    elif ext == \".rtf\":\n",
    "        return rtf_to_text(open(file_path, encoding=\"utf-8\").read())\n",
    "\n",
    "    elif ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        return pytesseract.image_to_string(Image.open(file_path))\n",
    "\n",
    "    elif ext == \".pdf\":\n",
    "        if force_ocr:\n",
    "            print(\"ðŸ” Force OCR enabled.\")\n",
    "            return ocr_pdf(file_path)\n",
    "\n",
    "        # Heuristic 1: file size\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"ðŸ“¦ File size: {size_mb:.2f} MB\")\n",
    "\n",
    "        if size_mb > 3.0:\n",
    "            print(\"ðŸ“¦ Large file size â†’ Using OCR\")\n",
    "            return ocr_pdf(file_path)\n",
    "\n",
    "        # Heuristic 2: avg text density\n",
    "        with fitz.open(file_path) as doc:\n",
    "            total_chars = 0\n",
    "            text = ''\n",
    "            for page in doc:\n",
    "                page_text = page.get_text()\n",
    "                total_chars += len(page_text)\n",
    "                text += page_text\n",
    "            avg_chars = total_chars / len(doc)\n",
    "            print(f\"ðŸ“Š Avg characters per page: {avg_chars:.2f}\")\n",
    "\n",
    "        if avg_chars < 50:\n",
    "            print(\"ðŸ§  Low content density â†’ OCR fallback\")\n",
    "            return ocr_pdf(file_path)\n",
    "\n",
    "        if len(text.strip()) < 100:\n",
    "            print(\"ðŸ” Very little text â†’ OCR fallback\")\n",
    "            return ocr_pdf(file_path)\n",
    "\n",
    "        return text\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "text = extract_text(file_path, force_ocr=force_ocr)\n",
    "print(\"\\n--- Extracted Text (first 1000 chars) ---\\n\")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d777d2",
   "metadata": {},
   "source": [
    "## ðŸ§  Generate Metadata (with LLMs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1562de4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "kw_model = KeyBERT(model=\"all-MiniLM-L6-v2\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "def extract_title(text):\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if 5 <= len(line.strip().split()) <= 15:\n",
    "            return line.strip()\n",
    "    return \"Untitled Document\"\n",
    "\n",
    "def extract_summary(text, max_chars=1024):\n",
    "    return summarizer(text[:max_chars], max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
    "\n",
    "def extract_keywords(text, top_n=5):\n",
    "    return kw_model.extract_keywords(text, top_n=top_n)  # returns (kw, score)\n",
    "\n",
    "def extract_date(text):\n",
    "    match = re.search(r\"\\d{4}[-/]\\d{2}[-/]\\d{2}|\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec).*?\\d{2,4}\", text, re.I)\n",
    "    return match.group(0) if match else \"Not found\"\n",
    "\n",
    "def detect_type(text):\n",
    "    labels = [\"resume\", \"declaration form\", \"research paper\", \"invoice\", \"application\", \"academic transcript\"]\n",
    "    result = classifier(text[:1024], labels)\n",
    "    return result[\"labels\"][0], round(result[\"scores\"][0] * 100, 2)\n",
    "\n",
    "def generate_metadata(text):\n",
    "    if not text.strip():\n",
    "        return {\n",
    "            \"title\": \"No content\",\n",
    "            \"summary\": \"\",\n",
    "            \"keywords\": [],\n",
    "            \"keyword_scores\": {},\n",
    "            \"document_type\": \"Unknown\",\n",
    "            \"detected_date\": \"Not found\"\n",
    "        }\n",
    "    title = extract_title(text)\n",
    "    summary = extract_summary(text)\n",
    "    \n",
    "    kw_raw = extract_keywords(text)\n",
    "    keywords = [kw[0] for kw in kw_raw]\n",
    "    keyword_scores = {kw[0]: round(kw[1], 3) for kw in kw_raw}\n",
    "\n",
    "    doc_type, confidence = detect_type(text)\n",
    "    detected_date = extract_date(text)\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"summary\": summary,\n",
    "        \"keywords\": keywords,\n",
    "        \"keyword_scores\": keyword_scores,\n",
    "        \"document_type\": f\"{doc_type} ({confidence}%)\",\n",
    "        \"detected_date\": detected_date\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9c9bbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Metadata Summary ---\n",
      "Title: arXiv:2506.18854v1  [astro-ph.HE]  23 Jun 2025\n",
      "Summary: Ailton J. B. JÂ´unior, â€  Leonardo J. Silvestre, â€¡ Thonimar V. Alencar and Wiliam S. HipÂ´olito-Ricaldi. arXiv:2506.18854v1  [astro-ph.HE] 23 Jun 2025.\n",
      "Keywords: astrophysics, astrophysical, bursts, astronomical, astrophysically\n",
      "\n",
      "Keyword_Scores:\n",
      "  - astrophysics: 0.394\n",
      "  - astrophysical: 0.373\n",
      "  - bursts: 0.359\n",
      "  - astronomical: 0.324\n",
      "  - astrophysically: 0.322\n",
      "Document_Type: declaration form (44.34%)\n",
      "Detected_Date: Jun 2025\n"
     ]
    }
   ],
   "source": [
    "metadata = generate_metadata(text)\n",
    "\n",
    "print(\"\\n--- Metadata Summary ---\")\n",
    "for k, v in metadata.items():\n",
    "    if isinstance(v, dict):  # For keyword_scores\n",
    "        print(f\"\\n{k.title()}:\")\n",
    "        for term, score in v.items():\n",
    "            print(f\"  - {term}: {score}\")\n",
    "    elif isinstance(v, list):\n",
    "        print(f\"{k.title()}: {', '.join(v)}\")\n",
    "    else:\n",
    "        print(f\"{k.title()}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a172f1",
   "metadata": {},
   "source": [
    "### Text Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e0166ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Text Stats:\n",
      "- Total Characters: 51851\n",
      "- Total Words: 7550\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nðŸ“ Text Stats:\\n- Total Characters: {len(text)}\\n- Total Words: {len(text.split())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0595e",
   "metadata": {},
   "source": [
    "### Keyword Relevance Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fedc40ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Keyword Relevance Table\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>astrophysics</th>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astrophysical</th>\n",
       "      <td>0.373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bursts</th>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astronomical</th>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astrophysically</th>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Relevance\n",
       "astrophysics         0.394\n",
       "astrophysical        0.373\n",
       "bursts               0.359\n",
       "astronomical         0.324\n",
       "astrophysically      0.322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"\\nðŸ“Š Keyword Relevance Table\")\n",
    "display(pd.DataFrame.from_dict(metadata[\"keyword_scores\"], orient=\"index\", columns=[\"Relevance\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98a7fb",
   "metadata": {},
   "source": [
    "## ðŸ“Š View Metadata as Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b1f4fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ðŸ“‹ Metadata Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>arXiv:2506.18854v1  [astro-ph.HE]  23 Jun 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summary</td>\n",
       "      <td>Ailton J. B. JÂ´unior, â€  Leonardo J. Silvestre,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keywords</td>\n",
       "      <td>[astrophysics, astrophysical, bursts, astronom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>document_type</td>\n",
       "      <td>declaration form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detected_date</td>\n",
       "      <td>Jun 2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Field                                              Value\n",
       "0          title     arXiv:2506.18854v1  [astro-ph.HE]  23 Jun 2025\n",
       "1        summary  Ailton J. B. JÂ´unior, â€  Leonardo J. Silvestre,...\n",
       "2       keywords  [astrophysics, astrophysical, bursts, astronom...\n",
       "3  document_type                                   declaration form\n",
       "4  detected_date                                           Jun 2025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(\"### ðŸ“‹ Metadata Summary\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd999cac",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Export Metadata (JSON + CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad716a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Exported as metadata.json and metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "df.to_csv(\"metadata.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Exported as metadata.json and metadata.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
